{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "\n",
    "# Given a model output directory :\n",
    "# 1. Output its overall performance train/dev/test\n",
    "# 2. Output its per slot performance train/dev/test\n",
    "# 3. Per slot comparison with other method e.g. baseline model\n",
    "# 4. \n",
    "def evaluate_conll(evaluable):\n",
    "    \"\"\"Evaluate sequence tagging hypothesis with CoNLL criteria.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> reference = [\n",
    "    ...     ['B-PER', 'I-PER', 'O'],\n",
    "    ...     ['B-LOC', 'I-LOC', 'I-LOC', 'O'],\n",
    "    ...     ['B-PER', 'I-PER', 'O', 'B-LOC', 'I-LOC'],\n",
    "    ...     ['O', 'B-PER']\n",
    "    ... ]\n",
    "    >>> hypothesis = [\n",
    "    ...     ['B-PER', 'I-PER', 'O'],\n",
    "    ...     ['B-PER', 'I-PER', 'I-PER', 'O'],\n",
    "    ...     ['O', 'B-PER', 'O', 'B-PER', 'O'],\n",
    "    ...     ['O', 'O']\n",
    "    ... ]\n",
    "    >>> evaluable = [zip(*sent_pair) for sent_pair in zip(reference, hypothesis)]\n",
    "    >>> overall, by_type = evaluate_conll(evaluable)\n",
    "    >>> '{0.precision:.2f} {0.recall:.2f}'.format(overall)\n",
    "    '0.25 0.20'\n",
    "    >>> '{0.precision:.2f} {0.recall:.2f}'.format(by_type['PER'])\n",
    "    '0.25 0.33'\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    evaluable : `iterable`_\n",
    "        An iterable of sentences where each sentence is an iterable of tag pairs. A tag pair\n",
    "        ``(ref_tag, hyp_tag)`` at position ``i`` means that the ``i``-th word in that sentence\n",
    "        has a true tag of ``ref_tag`` and a predicted tag of ``hyp_tag``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    overall : :obj:`~collections.namedtuple`\n",
    "         The overall evaluation result. Precision, recall, and F1 score can be accessed via\n",
    "         ``precision``, ``recall``, and ``f1_score`` attributes respectively.\n",
    "    by_type : :obj:`dict`\n",
    "         The evaluation result per tag type. The keys are the tag types (e.g. ``'PER'``)\n",
    "         and the values are namedtuples with the same structure as ``overall``.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This evaluation function supports both IOB and IOBES tagging.\n",
    "\n",
    "    .. _iterable:\n",
    "        https://docs.python.org/3/glossary.html#term-iterable\n",
    "    \"\"\"\n",
    "    return metrics(evaluate(chain(*evaluable)))\n",
    "\n",
    "\n",
    "class ConfusionMatrix:\n",
    "    \"\"\"A confusion matrix.\n",
    "\n",
    "    This class can be used to compute the confusion matrix of a multiclass\n",
    "    classification problem.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> reference  = 'a b a a b c'.split()\n",
    "    >>> hypothesis = 'a a c a b c'.split()\n",
    "    >>> cm = ConfusionMatrix(zip(reference, hypothesis))\n",
    "    >>> cm['a', 'a']  # actual class is 'a' and predicted as 'a'\n",
    "    2\n",
    "    >>> cm['a', 'b']  # actual class is 'a' but predicted as 'b'\n",
    "    0\n",
    "    >>> cm['a', 'c']  # actual class is 'a' but predicted as 'c'\n",
    "    1\n",
    "    >>> cm = ConfusionMatrix(zip(reference, hypothesis), marginalize=True)\n",
    "    >>> '{:.2f}'.format(cm['a', 'a'])\n",
    "    '0.67'\n",
    "    >>> '{:.2f}'.format(cm['a', 'b'])\n",
    "    '0.00'\n",
    "    >>> '{:.2f}'.format(cm['a', 'c'])\n",
    "    '0.33'\n",
    "    >>> print(cm)\n",
    "         |    a    b    c\n",
    "    -----+---------------\n",
    "    a    | 0.67    . 0.33\n",
    "    b    | 0.50 0.50    .\n",
    "    c    |    .    . 1.00\n",
    "    (row = reference, column = hypothesis)\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    pairs : `iterable`_\n",
    "        An iterable of ``(ref_class, hyp_class)`` tuple.\n",
    "    marginalize : bool\n",
    "        Whether to marginalize the confusion values over the hypothesis.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    marginalized : bool\n",
    "        Whether the confusion matrix is marginalized.\n",
    "    classes : list\n",
    "        List of all classes found in ``pairs``.\n",
    "    \"\"\"\n",
    "    def __init__(self, pairs, marginalize=False):\n",
    "        self.marginalized = marginalize\n",
    "\n",
    "        pairs = list(pairs)  # ensure pairs can be iterated twice\n",
    "        classes = set()\n",
    "        for ref, hyp in pairs:\n",
    "            classes.update((ref, hyp))\n",
    "        self.classes = list(classes)\n",
    "\n",
    "        self._cm = {}\n",
    "        for c1 in self.classes:\n",
    "            self._cm[c1] = {}\n",
    "            for c2 in self.classes:\n",
    "                # we don't use defaultdict because we want\n",
    "                # to raise an error if unseen pair is queried\n",
    "                self._cm[c1][c2] = 0\n",
    "        for ref, hyp in pairs:\n",
    "            assert ref in self._cm\n",
    "            assert hyp in self._cm[ref]\n",
    "            self._cm[ref][hyp] += 1\n",
    "\n",
    "        if marginalize:\n",
    "            for c1 in self._cm:\n",
    "                total = sum(self._cm[c1].values())\n",
    "                for c2 in self._cm[c1]:\n",
    "                    self._cm[c1][c2] /= total\n",
    "\n",
    "    def __getitem__(self, pair):\n",
    "        \"\"\"Get the confusion value of the given tuple of reference and hypothesis class.\"\"\"\n",
    "        ref, hyp = pair\n",
    "        return self._cm[ref][hyp]\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Return the confusion matrix as a pretty-formatted string.\"\"\"\n",
    "        # Convert everything to its string representation\n",
    "        classes = list(sorted(str(c) for c in self.classes))\n",
    "        cm = {str(c1): {str(c2): self._val2str(v) for c2, v in self._cm[c1].items()}\n",
    "              for c1 in self._cm}\n",
    "\n",
    "        # Compute column width\n",
    "        max_class_length = max(len(c) for c in classes)\n",
    "        max_val_length = max(len(val) for c in cm for val in cm[c].values())\n",
    "        colwidth = max(max_class_length, max_val_length) + 1  # account for margin\n",
    "\n",
    "        header = '{}|{}'.format(' ' * colwidth, ''.join([c.rjust(colwidth) for c in classes]))\n",
    "        rule = '{}+{}'.format('-' * colwidth, '-' * colwidth * len(classes))\n",
    "        out = [header, rule]\n",
    "        for c1 in classes:\n",
    "            first_col = c1.ljust(colwidth)\n",
    "            rem_cols = ''.join([cm[c1][c2].rjust(colwidth) for c2 in classes])\n",
    "            out.append('{}|{}'.format(first_col, rem_cols))\n",
    "        out.append('(row = reference, column = hypothesis)')\n",
    "        return '\\n'.join(out)\n",
    "\n",
    "    def to_array(self):\n",
    "        \"\"\"Return the confusion matrix as a NumPy array.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            The confusion matrix as NumPy array. The row and column order corresponds to\n",
    "            the order of the classes in :attr:`~ConfusionMatrix.classes`.\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        \n",
    "        return np.array([[self._cm[c1][c2] for c2 in self.classes] for c1 in self.classes])\n",
    "\n",
    "    def _val2str(self, val):\n",
    "        if self.marginalized:\n",
    "            return '.' if -1e-6 <= val <= 1e-6 else '{:.2f}'.format(val)\n",
    "        else:\n",
    "            return '.' if not val else str(val)\n",
    "\n",
    "\n",
    "def confusion_matrix_conll(evaluable, marginalize=False):\n",
    "    \"\"\"Compute confusion matrix of a CoNLL sequence tagging hypothesis.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> reference = [\n",
    "    ...     ['B-PER', 'I-PER', 'O'],\n",
    "    ...     ['B-LOC', 'I-LOC', 'I-LOC', 'O'],\n",
    "    ...     ['B-PER', 'I-PER', 'O', 'B-LOC', 'I-LOC'],\n",
    "    ...     ['O', 'B-PER'],\n",
    "    ...     ['B-ORG', 'B-ORG']\n",
    "    ... ]\n",
    "    >>> hypothesis = [\n",
    "    ...     ['B-PER', 'I-PER', 'O'],\n",
    "    ...     ['B-PER', 'I-PER', 'I-PER', 'O'],\n",
    "    ...     ['O', 'B-PER', 'O', 'B-PER', 'O'],\n",
    "    ...     ['O', 'O'],\n",
    "    ...     ['B-ORG', 'B-LOC']\n",
    "    ... ]\n",
    "    >>> evaluable = [zip(*sent_pair) for sent_pair in zip(reference, hypothesis)]\n",
    "    >>> cm = confusion_matrix_conll(evaluable)\n",
    "    >>> cm['O', 'PER']  # actual tag is O but predicted as PER\n",
    "    2\n",
    "    >>> cm['LOC', 'PER']  # actual tag is LOC but predicted as PER\n",
    "    1\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    evaluable : `iterable`_\n",
    "        An iterable of sentences where each sentence is an iterable of tag pairs. A tag pair\n",
    "        ``(ref_tag, hyp_tag)`` at position ``i`` means that the ``i``-th word in that sentence\n",
    "        has a true tag of ``ref_tag`` and a predicted tag of ``hyp_tag``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    :class:`ConfusionMatrix`\n",
    "        The confusion matrix.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function only supports IOB tagging.\n",
    "    \"\"\"\n",
    "    return ConfusionMatrix(cast_as_multiclass(evaluable), marginalize=marginalize)\n",
    "\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "Span = namedtuple('Span', 'start end tagname')\n",
    "\n",
    "\n",
    "def cast_as_multiclass(evaluable):\n",
    "    pairs = []\n",
    "    for sent in evaluable:\n",
    "        ref_sent, hyp_sent = zip(*sent)\n",
    "        ref_spans = find_spans(ref_sent)\n",
    "        hyp_spans = find_spans(hyp_sent)\n",
    "\n",
    "        matched_ref, matched_hyp = set(), set()\n",
    "        for i, ref_span in enumerate(ref_spans):\n",
    "            for j, hyp_span in enumerate(hyp_spans):\n",
    "                if match_exact(ref_span, hyp_span):\n",
    "                    # Found a match between reference and hypothesis\n",
    "                    matched_ref.add(i)\n",
    "                    matched_hyp.add(j)\n",
    "                    pairs.append((ref_span.tagname, hyp_span.tagname))\n",
    "                    break\n",
    "        # Unmatched spans are paired with O tags\n",
    "        for i, ref_span in enumerate(ref_spans):\n",
    "            if i not in matched_ref:\n",
    "                pairs.append((ref_span.tagname, 'O'))\n",
    "        for j, hyp_span in enumerate(hyp_spans):\n",
    "            if j not in matched_hyp:\n",
    "                pairs.append(('O', hyp_span.tagname))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def find_spans(tags):\n",
    "    spans = []\n",
    "    last_tagname = 'O'\n",
    "    last_start = -1\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag != 'O':\n",
    "            if tag.startswith('B-'):\n",
    "                # Found a new span; need to append the span seen previously, if any\n",
    "                if last_start >= 0:\n",
    "                    assert last_tagname != 'O'\n",
    "                    assert i > last_start\n",
    "                    spans.append(Span(last_start, i - 1, last_tagname))\n",
    "                last_tagname = tag[2:]\n",
    "                last_start = i\n",
    "            elif not tag.startswith('I-'):\n",
    "                raise ValueError('tag {} is not a valid IOB tag'.format(tag))\n",
    "            # TODO what if a span starts with I- tag?\n",
    "        elif last_start >= 0:\n",
    "            # Found O tag but we saw a span, so we append that\n",
    "            assert last_tagname != 'O'\n",
    "            assert i > last_start\n",
    "            spans.append(Span(last_start, i - 1, last_tagname))\n",
    "            last_tagname = 'O'\n",
    "            last_start = -1\n",
    "    # We reach EOS but we saw a span\n",
    "    if last_start >= 0:\n",
    "        assert last_tagname != 'O'\n",
    "        assert len(tags) > last_start\n",
    "        spans.append(Span(last_start, len(tags) - 1, last_tagname))\n",
    "    return spans\n",
    "\n",
    "\n",
    "def match_exact(span_a, span_b):\n",
    "    return span_a.start == span_b.start and span_a.end == span_b.end\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, save_to, marginalized=True):\n",
    "    # Import numpy and matplotlib here so users don't have to install\n",
    "    # them if they don't need to plot\n",
    "    import numpy as np\n",
    "    import matplotlib\n",
    "    matplotlib.use('AGG')  # use AGG backend because we only write to file\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    cmap = plt.cm.Blues\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    fmt = '{:.2f}' if marginalized else '{:d}'\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:,}\".format(cm[i, j]),horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('Reference')\n",
    "    plt.xlabel('Hypothesis')\n",
    "    plt.savefig(save_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util.CoNLL import readCoNLL, readOntoNotes\n",
    "\n",
    "# slots_stl = performance_per_slot(\"/Users/slouvan/sandbox/emnlp2017-bilstm-cnn-crf/results/SingleTask_ATIS_Full/predictions/ATIS_25_dev.conll\", out_file_name=\"SingleTask_ATIS_Full_ATIS_25_dev.tsv\")\n",
    "# slots_stl = performance_per_slot(\"/Users/slouvan/sandbox/emnlp2017-bilstm-cnn-crf/results/SingleTask_MIT_Restaurant_Full/predictions/MIT_Restaurant_13_dev.conll\", out_file_name=\"SingleTask_MIT_Restaurant_Full_MIT_Restaurant_13_dev.tsv\")\n",
    "# slots_stl = performance_per_slot(\"/Users/slouvan/sandbox/emnlp2017-bilstm-cnn-crf/results/SingleTask_MIT_Movie_Full/predictions/MIT_Movie_19_dev.conll\", out_file_name=\"STL_MIT_Movie_19_dev.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = readCoNLL(\"/Users/slouvan/sandbox/emnlp2017-bilstm-cnn-crf/results_emnlp/MIT_Restaurant_NER_ONLY_DIFFERENT_LEVEL/predictions/MIT_Restaurant_dev.conll\", {0:'tokens', 1:'reference', 2:'hypothesis'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = [ sentence['reference'] for sentence in sentences]\n",
    "hypothesis = [ sentence['hypothesis'] for sentence in sentences]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amenity', 'Cuisine', 'O', 'Hours', 'Restaurant_Name', 'Rating', 'Location', 'Price', 'Dish']\n",
      "[[367   8 167   0   2   2   2   1   1]\n",
      " [  9 438  43   6   2   0   0   0  21]\n",
      " [168  44   0  48  46  38 113  13  57]\n",
      " [  0   2  43 141   0   1   0   0   0]\n",
      " [  0   1  47   0 310   0   1   0   3]\n",
      " [  6   1  40   1   1 173   1   0   0]\n",
      " [  3   0 115   1   1   0 622   0   0]\n",
      " [  3   0  20   0   2   1   0 121   0]\n",
      " [  2  19  42   1  10   0   0   0 232]]\n"
     ]
    }
   ],
   "source": [
    "evaluable = [zip(*sent_pair) for sent_pair in zip(reference, hypothesis)]\n",
    "cm = confusion_matrix_conll(evaluable)\n",
    "str(cm).split('\\n') \n",
    "cm.classes\n",
    "print(cm.classes)\n",
    "print(cm.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm.to_array(), cm.classes, 'x.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amenity',\n",
       " 'Cuisine',\n",
       " 'O',\n",
       " 'Hours',\n",
       " 'Restaurant_Name',\n",
       " 'Rating',\n",
       " 'Location',\n",
       " 'Price',\n",
       " 'Dish']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                |         Amenity         Cuisine            Dish           Hours        Location               O           Price          Rating Restaurant_Name',\n",
       " '----------------+------------------------------------------------------------------------------------------------------------------------------------------------',\n",
       " 'Amenity         |             367               8               1               .               2             167               1               2               2',\n",
       " 'Cuisine         |               9             438              21               6               .              43               .               .               2',\n",
       " 'Dish            |               2              19             232               1               .              42               .               .              10',\n",
       " 'Hours           |               .               2               .             141               .              43               .               1               .',\n",
       " 'Location        |               3               .               .               1             622             115               .               .               1',\n",
       " 'O               |             168              44              57              48             113               .              13              38              46',\n",
       " 'Price           |               3               .               .               .               .              20             121               1               2',\n",
       " 'Rating          |               6               1               .               1               1              40               .             173               1',\n",
       " 'Restaurant_Name |               .               1               3               .               1              47               .               .             310',\n",
       " '(row = reference, column = hypothesis)']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(cm).split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukp",
   "language": "python",
   "name": "lxmls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
