{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from util.CoNLL import readCoNLL, readOntoNotes\n",
    "\n",
    "\n",
    "def convert_ontonotes_to_BIO(annotations) :\n",
    "    current_tag = None\n",
    "    inside_tag = False\n",
    "    BIO_annotations = []\n",
    "    for annotation in annotations:\n",
    "        if annotation[0] == \"(\" and annotation[len(annotation) - 1] == \")\" and current_tag is None :\n",
    "            if current_tag is None :\n",
    "                BIO_annotations.append(\"B-\"+annotation[1:len(annotation)-1])\n",
    "                #print(\"B-\"+annotation[1:len(annotation)-1])\n",
    "            else :\n",
    "                print(\"WRONG ANNOTATION\")\n",
    "        elif annotation[0] == \"(\" :\n",
    "            if current_tag is not None : \n",
    "                print(\"wrong annotation\")\n",
    "                raise(\"Error\")\n",
    "            else :\n",
    "                current_tag = annotation[1: len(annotation)-1]\n",
    "                BIO_annotations.append(\"B-\"+current_tag)\n",
    "                #print(\"Starting tag : {}\".format(current_tag))\n",
    "        elif annotation == \"*\" :\n",
    "            if current_tag is not None:\n",
    "                BIO_annotations.append(\"I-\"+current_tag)\n",
    "                #print(\"Currently inside : {}\".format(current_tag))\n",
    "            else :\n",
    "                BIO_annotations.append(\"O\")\n",
    "                current_tag = None\n",
    "                #print(\"Outside\")\n",
    "        elif annotation == \"*)\":\n",
    "            if current_tag is not None :\n",
    "                BIO_annotations.append(\"I-\"+current_tag)\n",
    "                current_tag = None\n",
    "            else :\n",
    "                print(\"WRONG ANNOTATION\")\n",
    "    #print(annotations)\n",
    "    #print(BIO_annotations)\n",
    "    #print(\"=======================================\")\n",
    "    return BIO_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = readOntoNotes(\"/Users/slouvan/sandbox/cross-domain/data/conll-formatted-ontonotes-5.0/data/train/data/english/annotations/bc/cnn/00/cnn_0001.gold_conll\",{3:'tokens', 10:'OntoNotes_Label'}, commentSymbol=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    annotations = sentence['OntoNotes_Label']\n",
    "    BIO_annotations = convert_ontonotes_to_BIO(annotations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PER', 'I-PER', 'I-PER', 'B-ORG', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_ontonotes_to_BIO(['(PER*', '*', '*)', '(ORG)','(LOC*','*','*', '*)', '*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12217\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_dir = \"/Users/slouvan/sandbox/cross-domain/data/conll-formatted-ontonotes-5.0/data/test/data/english/annotations\"\n",
    "total_sentences = 0\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        current_file = os.path.join(subdir, file)\n",
    "        if current_file.endswith(\".gold_conll\"):\n",
    "            sentences = readOntoNotes(current_file,{3:'tokens', 10:'OntoNotes_Label'}, commentSymbol=\"#\")\n",
    "            for idx, sentence in enumerate(sentences):\n",
    "                annotations = sentences[idx]['OntoNotes_Label']\n",
    "                BIO_annotations = convert_ontonotes_to_BIO(annotations)\n",
    "                sentences[idx]['OntoNotes_BIO'] = BIO_annotations\n",
    "            \n",
    "            with open(current_file+\".bio\", \"w\") as f:\n",
    "                for sentence in sentences:\n",
    "                    BIO_annotations = sentence['OntoNotes_BIO']\n",
    "                    tokens = sentence['tokens']\n",
    "                    for idx, token in enumerate(tokens):\n",
    "                        f.write(\"{} {}\\n\".format(tokens[idx], BIO_annotations[idx]))\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "            total_sentences += len(sentences)\n",
    "print(total_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = readCoNLL(\"/Users/slouvan/sandbox/cross-domain/data/conll-formatted-ontonotes-5.0/data/development/data/english/annotations/bc/cnn/00/cnn_0000.gold_conll.bio\",{0:'tokens', 1:'OntoNotes_Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6911\n"
     ]
    }
   ],
   "source": [
    "path =  \"/Users/slouvan/sandbox/cross-domain/data/conll-formatted-ontonotes-5.0/data/train/data/english/annotations/mz\"\n",
    "nb_sentence = 0\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    for file in files :\n",
    "        current_file = os.path.join(subdir, file)\n",
    "        if current_file.endswith(\".bio\") :\n",
    "            sentences = readCoNLL(current_file,{0:'tokens', 1:'OntoNotes_Label'})\n",
    "            nb_sentence += len(sentences)\n",
    "print(nb_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences : 10683\n",
      "Label freq per tag : defaultdict(<class 'int'>, {'EVENT': 111, 'PRODUCT': 327, 'MONEY': 177, 'PERCENT': 132, 'QUANTITY': 126, 'PERSON': 4242, 'DATE': 2351, 'ORG': 2468, 'TIME': 517, 'LANGUAGE': 22, 'LOC': 373, 'LAW': 25, 'CARDINAL': 1639, 'WORK_OF_ART': 160, 'ORDINAL': 366, 'FAC': 275, 'NORP': 2394, 'GPE': 4056})\n",
      "Total tag freq : 19761\n",
      "Total nb tag : 18\n",
      "Average tag per sent : 1.849761303004774\n",
      "Total sentences : 1295\n",
      "Label freq per tag : defaultdict(<class 'int'>, {'EVENT': 14, 'PERCENT': 21, 'WORK_OF_ART': 26, 'ORG': 303, 'PERSON': 557, 'DATE': 302, 'QUANTITY': 19, 'PRODUCT': 35, 'TIME': 68, 'LANGUAGE': 7, 'LOC': 42, 'LAW': 6, 'CARDINAL': 155, 'MONEY': 14, 'ORDINAL': 53, 'FAC': 24, 'NORP': 244, 'GPE': 516})\n",
      "Total tag freq : 2406\n",
      "Total nb tag : 18\n",
      "Average tag per sent : 1.8579150579150578\n",
      "Total sentences : 1357\n",
      "Label freq per tag : defaultdict(<class 'int'>, {'EVENT': 24, 'MONEY': 20, 'PERCENT': 6, 'DATE': 318, 'PERSON': 460, 'ORG': 264, 'QUANTITY': 16, 'PRODUCT': 43, 'TIME': 54, 'LANGUAGE': 5, 'LOC': 60, 'LAW': 4, 'CARDINAL': 196, 'WORK_OF_ART': 35, 'ORDINAL': 47, 'FAC': 36, 'NORP': 304, 'GPE': 537})\n",
      "Total tag freq : 2429\n",
      "Total nb tag : 18\n",
      "Average tag per sent : 1.7899778924097274\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "def exist(list_of_names, my_str):\n",
    "    for name in list_of_names:\n",
    "        if name in my_str:\n",
    "            return True\n",
    "    return False\n",
    "            \n",
    "\n",
    "\"\"\"\n",
    "This function read the raw OntoNotes 5.0 data. As the data is very large, \n",
    "We should be able to select particular domain to train\n",
    "\"\"\"\n",
    "def create_onto_notes_dataset(path_to_data, domain=[]):\n",
    "    nb_sentence = 0\n",
    "    all_sentences = []\n",
    "    label_count = defaultdict(int)\n",
    "    for subdir, dirs, files in os.walk(path_to_data):\n",
    "        for file in files :\n",
    "            current_file = os.path.join(subdir, file)\n",
    "            if len(domain) > 0:\n",
    "                if exist(domain, current_file) and  current_file.endswith(\".bio\") :\n",
    "                    sentences = readCoNLL(current_file,{0:'tokens', 1:'OntoNotes_Label'})\n",
    "                    #print(sentences[0])\n",
    "                    all_sentences += sentences\n",
    "                    for sent in sentences :\n",
    "                        annotations = sent['OntoNotes_Label']\n",
    "                        for annotation in annotations :\n",
    "                            if annotation.startswith(\"B-\"):\n",
    "                                field = annotation.split(\"B-\")\n",
    "                                label_count[field[1]] += 1\n",
    "                    nb_sentence += len(sentences)\n",
    "    print(\"Total sentences : {}\".format(nb_sentence))\n",
    "    print(\"Label freq per tag : {}\".format(label_count))\n",
    "    total_tag_freq = sum(list(label_count.values()))\n",
    "    print(\"Total tag freq : {}\".format(sum(list(label_count.values()))))\n",
    "    print(\"Total nb tag : {}\".format(len(label_count)))\n",
    "    print(\"Average tag per sent : {}\".format(total_tag_freq/nb_sentence))\n",
    "    \n",
    "    return all_sentences\n",
    "\n",
    "\n",
    "train_sents = create_onto_notes_dataset(\"/Users/slouvan/sandbox/cross-domain/data/conll-formatted-ontonotes-5.0/data/train/data/english/annotations\",[ \"annotations/bn\"]) \n",
    "dev_sents   = create_onto_notes_dataset(\"/Users/slouvan/sandbox/cross-domain/data/conll-formatted-ontonotes-5.0/data/development/data/english/annotations\",[ \"annotations/bn\"]) \n",
    "test_sents  = create_onto_notes_dataset(\"/Users/slouvan/sandbox/cross-domain/data/conll-formatted-ontonotes-5.0/data/test/data/english/annotations\",[ \"annotations/bn\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dumpConll(outputPath, sentences, headers):\n",
    "    \"\"\"\n",
    "    Writes a sentences array/hashmap to a CoNLL format\n",
    "    \"\"\"\n",
    "    if not os.path.exists(os.path.dirname(outputPath)):\n",
    "        os.makedirs(os.path.dirname(outputPath))\n",
    "    fOut = open(outputPath, 'w')\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for idx in range(len(sentence['tokens'])):\n",
    "            fOut.write(sentence[headers[0]][idx]+\" \"+sentence[headers[1]][idx]+\"\\n\")\n",
    "\n",
    "        fOut.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dumpConll(\"/Users/slouvan/sandbox/emnlp2017-bilstm-cnn-crf/data/OntoNotes_BN/train.txt\", train_sents,{0:'tokens', 1:'OntoNotes_Label'})\n",
    "dumpConll(\"/Users/slouvan/sandbox/emnlp2017-bilstm-cnn-crf/data/OntoNotes_BN/dev.txt\",   dev_sents,{0:'tokens', 1:'OntoNotes_Label'})\n",
    "dumpConll(\"/Users/slouvan/sandbox/emnlp2017-bilstm-cnn-crf/data/OntoNotes_BN/test.txt\",  test_sents,{0:'tokens', 1:'OntoNotes_Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukp",
   "language": "python",
   "name": "lxmls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
